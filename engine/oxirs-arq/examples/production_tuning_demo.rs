//! Production Tuning Demonstration
//!
//! This example shows how to use different optimizer configurations
//! for various production workload profiles.
//!
//! # Usage
//!
//! ```bash
//! cargo run --example production_tuning_demo --features star
//! ```

use oxirs_arq::optimizer::{ProductionOptimizerConfig, WorkloadProfile};

fn main() -> anyhow::Result<()> {
    println!("=== Production Optimizer Tuning Guide ===\n");

    println!("This guide demonstrates workload-specific optimizer configurations");
    println!("for achieving optimal performance in different deployment scenarios.\n");

    // Part 1: High Throughput OLTP
    println!("ğŸ“Š Profile 1: High-Throughput OLTP");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::HighThroughput);

    // Part 2: Analytical Queries OLAP
    println!("\nğŸ“ˆ Profile 2: Analytical Queries (OLAP)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::AnalyticalQueries);

    // Part 3: Mixed Workload
    println!("\nâš–ï¸  Profile 3: Mixed Workload");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::Mixed);

    // Part 4: Low Memory
    println!("\nğŸ’¾ Profile 4: Low Memory (Edge/Container)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::LowMemory);

    // Part 5: Low CPU
    println!("\nğŸ”‹ Profile 5: Low CPU (Resource Constrained)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::LowCpu);

    // Part 6: Maximum Performance
    println!("\nğŸš€ Profile 6: Maximum Performance");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    demo_profile(WorkloadProfile::MaxPerformance);

    // Summary and Recommendations
    println!("\nâœ¨ Production Deployment Recommendations");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    print_recommendations();

    println!("\nâœ… Demo complete! Choose the profile that matches your workload.\n");

    Ok(())
}

fn demo_profile(profile: WorkloadProfile) {
    let config = ProductionOptimizerConfig::for_workload(profile);

    println!("Workload Profile: {:?}", profile);
    println!("\nOptimizer Settings:");
    println!(
        "  â€¢ Join Reordering: {}",
        config.base_config.join_reordering
    );
    println!(
        "  â€¢ Filter Pushdown: {}",
        config.base_config.filter_pushdown
    );
    println!(
        "  â€¢ Cost-Based Optimization: {}",
        config.base_config.cost_based
    );
    println!(
        "  â€¢ Max Optimization Passes: {}",
        config.base_config.max_passes
    );
    println!("  â€¢ Estimation Method: {:?}", config.estimation_method);

    println!("\nCaching Configuration:");
    println!(
        "  â€¢ Plan Cache Size: {} queries",
        config.max_plan_cache_size
    );
    println!(
        "  â€¢ Result Cache: {}",
        if config.enable_result_cache {
            "Enabled"
        } else {
            "Disabled"
        }
    );
    if config.enable_result_cache {
        println!(
            "  â€¢ Result Cache TTL: {} seconds",
            config.result_cache_ttl_secs
        );
    }

    println!("\nAdaptive Learning:");
    println!("  â€¢ Adaptive Learning: {}", config.adaptive_learning);
    if config.adaptive_learning {
        println!(
            "  â€¢ ML Training Threshold: {} samples",
            config.ml_training_threshold
        );
        println!(
            "  â€¢ Stats Update Frequency: every {} queries",
            config.stats_update_frequency
        );
    }

    let resources = config.estimate_resource_requirements();
    println!("\nResource Requirements:");
    println!("  â€¢ Memory: ~{}MB", resources.memory_mb);
    println!("  â€¢ CPU Cores: {} recommended", resources.cpu_cores);
    println!("  â€¢ Cache Memory: ~{}MB", resources.cache_memory_mb);
    println!(
        "  â€¢ Max Concurrent Queries: {}",
        resources.max_concurrent_queries
    );

    // Validate configuration
    let warnings = config.validate();
    if !warnings.is_empty() {
        println!("\nâš ï¸  Configuration Warnings:");
        for warning in warnings {
            println!("  â€¢ {}", warning);
        }
    } else {
        println!("\nâœ“ Configuration validated - no warnings");
    }

    // Print use cases
    println!("\nğŸ¯ Best For:");
    match profile {
        WorkloadProfile::HighThroughput => {
            println!("  â€¢ Simple queries (2-5 triple patterns)");
            println!("  â€¢ High query rate (>1000 QPS)");
            println!("  â€¢ Low latency requirements (<10ms p95)");
            println!("  â€¢ Repeated query patterns");
            println!("  â€¢ E-commerce, real-time APIs, web applications");
        }
        WorkloadProfile::AnalyticalQueries => {
            println!("  â€¢ Complex queries (10-100 triple patterns)");
            println!("  â€¢ Low query rate (<10 QPS)");
            println!("  â€¢ Large result sets (>10K rows)");
            println!("  â€¢ Data warehousing, business intelligence");
            println!("  â€¢ Ad-hoc analytical queries");
        }
        WorkloadProfile::Mixed => {
            println!("  â€¢ Combination of simple and complex queries");
            println!("  â€¢ Moderate query rate (10-1000 QPS)");
            println!("  â€¢ Variable result sizes");
            println!("  â€¢ General-purpose SPARQL endpoints");
            println!("  â€¢ Most production deployments");
        }
        WorkloadProfile::LowMemory => {
            println!("  â€¢ Limited RAM (<2GB available)");
            println!("  â€¢ Containerized deployments (Docker, Kubernetes)");
            println!("  â€¢ Edge computing devices");
            println!("  â€¢ Embedded systems");
            println!("  â€¢ Development/testing environments");
        }
        WorkloadProfile::LowCpu => {
            println!("  â€¢ CPU-constrained environments");
            println!("  â€¢ Shared hosting");
            println!("  â€¢ Mobile/IoT devices");
            println!("  â€¢ Minimizing CPU usage");
            println!("  â€¢ Battery-powered devices");
        }
        WorkloadProfile::MaxPerformance => {
            println!("  â€¢ Dedicated servers (16+ cores, 32GB+ RAM)");
            println!("  â€¢ Mission-critical queries");
            println!("  â€¢ Maximum optimization needed");
            println!("  â€¢ Premium hosting environments");
            println!("  â€¢ Research/academic workloads");
        }
    }

    println!("\nğŸ’¡ Configuration Tips:");
    match profile {
        WorkloadProfile::HighThroughput => {
            println!("  â€¢ Use aggressive plan caching for repeated queries");
            println!("  â€¢ Minimize optimization overhead with fewer passes");
            println!("  â€¢ Enable result caching for frequently-run queries");
            println!("  â€¢ Consider read replicas for scaling beyond 1K QPS");
        }
        WorkloadProfile::AnalyticalQueries => {
            println!("  â€¢ Enable ML-based cardinality estimation");
            println!("  â€¢ Use adaptive learning to improve over time");
            println!("  â€¢ Allocate more resources for complex optimizations");
            println!("  â€¢ Monitor query execution for bottleneck identification");
        }
        WorkloadProfile::Mixed => {
            println!("  â€¢ Balance between optimization depth and speed");
            println!("  â€¢ Use histogram-based estimation for good accuracy");
            println!("  â€¢ Enable adaptive learning for workload adaptation");
            println!("  â€¢ Monitor workload patterns and adjust if skewed");
        }
        WorkloadProfile::LowMemory => {
            println!("  â€¢ Disable result caching if memory is critical");
            println!("  â€¢ Use HyperLogLog sketches (only 16KB per predicate)");
            println!("  â€¢ Minimize plan cache size (100 plans = ~100KB)");
            println!("  â€¢ Consider streaming results instead of materialization");
        }
        WorkloadProfile::LowCpu => {
            println!("  â€¢ Rely on plan and result caching to avoid re-computation");
            println!("  â€¢ Use simple heuristics instead of cost-based optimization");
            println!("  â€¢ Limit optimization passes to 2-3");
            println!("  â€¢ Enable filter pushdown for early pruning");
        }
        WorkloadProfile::MaxPerformance => {
            println!("  â€¢ Enable all optimizations (30 passes)");
            println!("  â€¢ Use large caches (50K plans, 2-hour TTL)");
            println!("  â€¢ Train ML models aggressively (50 sample threshold)");
            println!("  â€¢ Monitor and tune based on actual query patterns");
        }
    }
}

fn print_recommendations() {
    println!("ğŸ¯ Quick Selection Guide:");
    println!("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("   â”‚ Your Scenario        â”‚ Recommended Profile             â”‚");
    println!("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    println!("   â”‚ REST API (<10ms)     â”‚ HighThroughput                  â”‚");
    println!("   â”‚ Business Intelligenceâ”‚ AnalyticalQueries               â”‚");
    println!("   â”‚ General SPARQL       â”‚ Mixed (default)                 â”‚");
    println!("   â”‚ Docker/K8s (<2GB)    â”‚ LowMemory                       â”‚");
    println!("   â”‚ Edge Device          â”‚ LowCpu or LowMemory             â”‚");
    println!("   â”‚ Dedicated Server     â”‚ MaxPerformance                  â”‚");
    println!("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    println!("\nğŸ“ˆ Performance Expectations:");
    println!("   â€¢ HighThroughput: 1000+ QPS, <10ms p95 latency");
    println!("   â€¢ AnalyticalQueries: 5-10 QPS, optimized for complex queries");
    println!("   â€¢ Mixed: 100-500 QPS, balanced performance");
    println!("   â€¢ LowMemory: 50-100 QPS with <100MB overhead");
    println!("   â€¢ LowCpu: 20-50 QPS, minimal CPU usage");
    println!("   â€¢ MaxPerformance: 500+ QPS with advanced optimization");

    println!("\nğŸ”§ Advanced Tuning:");
    println!("   1. Start with recommended profile");
    println!("   2. Monitor actual query patterns and performance");
    println!("   3. Adjust cache sizes based on hit rates");
    println!("   4. Enable adaptive learning for workload-specific optimization");
    println!("   5. Use ML estimation after collecting 100+ execution samples");

    println!("\nğŸ“Š Monitoring Recommendations:");
    println!("   â€¢ Track cache hit rates (target: >80% for repeated queries)");
    println!("   â€¢ Monitor optimization overhead (should be <10% of execution time)");
    println!("   â€¢ Measure p95/p99 latencies for SLA compliance");
    println!("   â€¢ Watch memory usage trends for cache sizing");
    println!("   â€¢ Profile slow queries for optimization opportunities");

    println!("\nâš¡ Quick Wins:");
    println!("   âœ“ Enable plan caching for 2-5x speedup on repeated queries");
    println!("   âœ“ Use result caching for 10-100x speedup on identical queries");
    println!("   âœ“ Enable filter pushdown for 3-10x reduction in intermediate results");
    println!("   âœ“ Train ML model for 20-50% cardinality estimation improvement");
    println!("   âœ“ Use cost-based join ordering for 2-10x speedup on complex joins");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_all_profiles() {
        let profiles = vec![
            WorkloadProfile::HighThroughput,
            WorkloadProfile::AnalyticalQueries,
            WorkloadProfile::Mixed,
            WorkloadProfile::LowMemory,
            WorkloadProfile::LowCpu,
            WorkloadProfile::MaxPerformance,
        ];

        for profile in profiles {
            println!("Testing profile: {:?}", profile);
            demo_profile(profile);
        }
    }
}
