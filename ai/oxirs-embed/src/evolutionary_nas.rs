//! Evolutionary Neural Architecture Search for Advanced Embedding Architectures
//!
//! This module implements state-of-the-art neural architecture search using evolutionary
//! algorithms, genetic programming, and advanced optimization techniques to automatically
//! discover optimal embedding architectures for specific knowledge graph domains.
//!
//! Features:
//! - Multi-objective evolutionary optimization (accuracy vs efficiency)
//! - Advanced genetic programming with crossover and mutation
//! - Architecture encoding with graph-based representations
//! - Population diversity maintenance and novelty search
//! - Progressive complexification and modular architecture building
//! - Hardware-aware optimization for different deployment targets

use crate::{EmbeddingModel, ModelConfig, ModelStats, Vector};
use anyhow::{anyhow, Result};
use scirs2_core::ndarray_ext::{Array1, Array2, Array3, Axis};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tracing::{debug, info, warn, error};
use uuid::Uuid;
use scirs2_core::random::{seq::SliceRandom, rng, Random};

/// Evolutionary Neural Architecture Search Engine
pub struct EvolutionaryNAS {
    /// Configuration for evolutionary search
    config: EvolutionaryConfig,
    /// Current population of architectures
    population: Arc<RwLock<Vec<ArchitectureCandidate>>>,
    /// Evolution history and statistics
    evolution_history: EvolutionHistory,
    /// Fitness evaluator for architectures
    fitness_evaluator: FitnessEvaluator,
    /// Genetic operators for evolution
    genetic_operators: GeneticOperators,
    /// Population diversity manager
    diversity_manager: DiversityManager,
    /// Hardware-aware optimizer
    hardware_optimizer: HardwareOptimizer,
    /// Architecture performance cache
    performance_cache: Arc<RwLock<HashMap<String, PerformanceMetrics>>>,
}

/// Configuration for evolutionary neural architecture search
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvolutionaryConfig {
    /// Population size for evolution
    pub population_size: usize,
    /// Number of generations to evolve
    pub max_generations: usize,
    /// Elite selection percentage (preserved each generation)
    pub elite_percentage: f32,
    /// Tournament selection size
    pub tournament_size: usize,
    /// Crossover probability
    pub crossover_probability: f32,
    /// Mutation probability per gene
    pub mutation_probability: f32,
    /// Diversity maintenance strength
    pub diversity_strength: f32,
    /// Multi-objective weights (accuracy, efficiency, complexity)
    pub objective_weights: ObjectiveWeights,
    /// Target hardware configuration
    pub target_hardware: HardwareTarget,
    /// Progressive complexification settings
    pub progressive_config: ProgressiveConfig,
}

impl Default for EvolutionaryConfig {
    fn default() -> Self {
        Self {
            population_size: 50,
            max_generations: 100,
            elite_percentage: 0.1,
            tournament_size: 5,
            crossover_probability: 0.8,
            mutation_probability: 0.1,
            diversity_strength: 0.3,
            objective_weights: ObjectiveWeights::default(),
            target_hardware: HardwareTarget::default(),
            progressive_config: ProgressiveConfig::default(),
        }
    }
}

/// Multi-objective optimization weights
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ObjectiveWeights {
    /// Weight for model accuracy
    pub accuracy_weight: f32,
    /// Weight for computational efficiency
    pub efficiency_weight: f32,
    /// Weight for memory usage
    pub memory_weight: f32,
    /// Weight for architecture simplicity
    pub simplicity_weight: f32,
    /// Weight for innovation/novelty
    pub novelty_weight: f32,
}

impl Default for ObjectiveWeights {
    fn default() -> Self {
        Self {
            accuracy_weight: 0.4,
            efficiency_weight: 0.3,
            memory_weight: 0.15,
            simplicity_weight: 0.1,
            novelty_weight: 0.05,
        }
    }
}

/// Target hardware configuration for optimization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum HardwareTarget {
    /// High-performance GPU cluster
    HighPerformanceGPU {
        gpu_memory_gb: f32,
        compute_capability: f32,
        parallelism_factor: f32,
    },
    /// Edge computing device
    EdgeDevice {
        cpu_cores: usize,
        memory_mb: f32,
        power_budget_watts: f32,
    },
    /// Cloud deployment
    CloudDeployment {
        instance_type: String,
        cost_per_hour: f32,
        scaling_factor: f32,
    },
    /// Neuromorphic hardware
    NeuromorphicChip {
        neuron_count: usize,
        synapse_count: usize,
        spike_rate_khz: f32,
    },
}

impl Default for HardwareTarget {
    fn default() -> Self {
        Self::HighPerformanceGPU {
            gpu_memory_gb: 16.0,
            compute_capability: 8.0,
            parallelism_factor: 1.0,
        }
    }
}

/// Progressive complexification configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProgressiveConfig {
    /// Start with simple architectures
    pub start_complexity: usize,
    /// Maximum architecture complexity
    pub max_complexity: usize,
    /// Complexity increase rate per generation
    pub complexity_increase_rate: f32,
    /// Enable modular architecture building
    pub enable_modular_building: bool,
    /// Module library for reuse
    pub enable_module_library: bool,
}

impl Default for ProgressiveConfig {
    fn default() -> Self {
        Self {
            start_complexity: 3,
            max_complexity: 20,
            complexity_increase_rate: 0.1,
            enable_modular_building: true,
            enable_module_library: true,
        }
    }
}

/// Architecture candidate in the population
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchitectureCandidate {
    /// Unique identifier
    pub id: Uuid,
    /// Architecture genome representation
    pub genome: ArchitectureGenome,
    /// Fitness scores for multi-objective optimization
    pub fitness: FitnessScores,
    /// Performance metrics
    pub performance: Option<PerformanceMetrics>,
    /// Generation when created
    pub generation: usize,
    /// Parent candidates (for lineage tracking)
    pub parents: Vec<Uuid>,
    /// Novelty score for diversity
    pub novelty_score: f32,
    /// Hardware efficiency metrics
    pub hardware_metrics: HardwareMetrics,
}

/// Architecture genome representation using graph-based encoding
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchitectureGenome {
    /// Node types in the architecture graph
    pub nodes: Vec<NodeGene>,
    /// Connections between nodes
    pub connections: Vec<ConnectionGene>,
    /// Global architecture parameters
    pub global_params: GlobalParameters,
    /// Module definitions for reuse
    pub modules: Vec<ModuleDefinition>,
}

/// Node gene representing a layer or operation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeGene {
    /// Node identifier
    pub id: usize,
    /// Type of operation
    pub operation: OperationType,
    /// Operation-specific parameters
    pub parameters: HashMap<String, f32>,
    /// Whether this node is active
    pub active: bool,
    /// Innovation number for genetic tracking
    pub innovation_number: usize,
}

/// Connection gene representing data flow
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConnectionGene {
    /// Source node ID
    pub from_node: usize,
    /// Target node ID
    pub to_node: usize,
    /// Connection weight
    pub weight: f32,
    /// Whether this connection is active
    pub active: bool,
    /// Innovation number for genetic tracking
    pub innovation_number: usize,
}

/// Types of operations available for architecture building
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum OperationType {
    /// Linear transformation
    Linear { input_dim: usize, output_dim: usize },
    /// Convolutional layer
    Convolution { filters: usize, kernel_size: usize },
    /// Graph convolution
    GraphConv { channels: usize, aggregation: String },
    /// Attention mechanism
    Attention { heads: usize, embed_dim: usize },
    /// Transformer block
    Transformer { layers: usize, heads: usize },
    /// Embedding layer
    Embedding { vocab_size: usize, embed_dim: usize },
    /// Activation function
    Activation { function: String },
    /// Normalization layer
    Normalization { method: String },
    /// Dropout regularization
    Dropout { rate: f32 },
    /// Skip connection
    SkipConnection,
    /// Pooling operation
    Pooling { method: String, size: usize },
    /// Custom operation (for novel architectures)
    Custom { operation_id: String, params: HashMap<String, f32> },
}

/// Global parameters affecting the entire architecture
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GlobalParameters {
    /// Base learning rate
    pub learning_rate: f32,
    /// Optimizer type
    pub optimizer: String,
    /// Regularization strength
    pub regularization: f32,
    /// Batch size
    pub batch_size: usize,
    /// Number of training epochs
    pub epochs: usize,
}

impl Default for GlobalParameters {
    fn default() -> Self {
        Self {
            learning_rate: 0.001,
            optimizer: "adam".to_string(),
            regularization: 0.01,
            batch_size: 32,
            epochs: 100,
        }
    }
}

/// Module definition for modular architecture building
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleDefinition {
    /// Module identifier
    pub id: String,
    /// Nodes in this module
    pub nodes: Vec<NodeGene>,
    /// Internal connections
    pub connections: Vec<ConnectionGene>,
    /// Input/output specifications
    pub interface: ModuleInterface,
    /// Performance characteristics
    pub characteristics: ModuleCharacteristics,
}

/// Module interface specification
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleInterface {
    /// Input dimension
    pub input_dim: usize,
    /// Output dimension
    pub output_dim: usize,
    /// Input types accepted
    pub input_types: Vec<String>,
    /// Output types produced
    pub output_types: Vec<String>,
}

/// Module performance characteristics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleCharacteristics {
    /// Computational complexity (FLOPs)
    pub computational_cost: f64,
    /// Memory requirements (bytes)
    pub memory_cost: f64,
    /// Typical accuracy contribution
    pub accuracy_contribution: f32,
    /// Stability metric
    pub stability: f32,
}

/// Fitness scores for multi-objective optimization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FitnessScores {
    /// Overall fitness (weighted combination)
    pub overall_fitness: f32,
    /// Accuracy on validation set
    pub accuracy: f32,
    /// Computational efficiency score
    pub efficiency: f32,
    /// Memory efficiency score
    pub memory_efficiency: f32,
    /// Architecture simplicity score
    pub simplicity: f32,
    /// Novelty/innovation score
    pub novelty: f32,
    /// Hardware compatibility score
    pub hardware_compatibility: f32,
    /// Pareto rank for multi-objective optimization
    pub pareto_rank: usize,
    /// Crowding distance for diversity
    pub crowding_distance: f32,
}

impl Default for FitnessScores {
    fn default() -> Self {
        Self {
            overall_fitness: 0.0,
            accuracy: 0.0,
            efficiency: 0.0,
            memory_efficiency: 0.0,
            simplicity: 0.0,
            novelty: 0.0,
            hardware_compatibility: 0.0,
            pareto_rank: 0,
            crowding_distance: 0.0,
        }
    }
}

/// Performance metrics for architecture evaluation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    /// Training accuracy
    pub training_accuracy: f32,
    /// Validation accuracy
    pub validation_accuracy: f32,
    /// Test accuracy (if available)
    pub test_accuracy: Option<f32>,
    /// Training time (seconds)
    pub training_time: f64,
    /// Inference time per sample (milliseconds)
    pub inference_time_ms: f32,
    /// Memory usage (MB)
    pub memory_usage_mb: f32,
    /// Energy consumption (Joules)
    pub energy_consumption: Option<f32>,
    /// Model size (parameters)
    pub model_size: usize,
    /// FLOPs for forward pass
    pub flops: u64,
}

/// Hardware-specific metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HardwareMetrics {
    /// GPU utilization percentage
    pub gpu_utilization: f32,
    /// Memory utilization percentage
    pub memory_utilization: f32,
    /// Theoretical throughput (samples/second)
    pub throughput: f32,
    /// Power consumption (Watts)
    pub power_consumption: f32,
    /// Hardware efficiency score
    pub efficiency_score: f32,
}

impl Default for HardwareMetrics {
    fn default() -> Self {
        Self {
            gpu_utilization: 0.0,
            memory_utilization: 0.0,
            throughput: 0.0,
            power_consumption: 0.0,
            efficiency_score: 0.0,
        }
    }
}

/// Evolution history tracking
pub struct EvolutionHistory {
    /// Generation statistics
    generation_stats: Vec<GenerationStatistics>,
    /// Best architectures found
    hall_of_fame: VecDeque<ArchitectureCandidate>,
    /// Innovation tracking
    innovation_tracker: InnovationTracker,
    /// Convergence metrics
    convergence_metrics: ConvergenceMetrics,
}

/// Statistics for each generation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GenerationStatistics {
    /// Generation number
    pub generation: usize,
    /// Best fitness in generation
    pub best_fitness: f32,
    /// Average fitness
    pub average_fitness: f32,
    /// Fitness standard deviation
    pub fitness_std: f32,
    /// Population diversity score
    pub diversity_score: f32,
    /// Number of new innovations
    pub new_innovations: usize,
    /// Generation timestamp
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

/// Innovation tracking for genetic operators
pub struct InnovationTracker {
    /// Next innovation number
    next_innovation: usize,
    /// Innovation history
    innovation_history: HashMap<String, usize>,
    /// Innovation to fitness mapping
    innovation_fitness: HashMap<usize, f32>,
}

impl InnovationTracker {
    pub fn new() -> Self {
        Self {
            next_innovation: 1,
            innovation_history: HashMap::new(),
            innovation_fitness: HashMap::new(),
        }
    }

    pub fn get_innovation_number(&mut self, innovation_key: &str) -> usize {
        if let Some(&innovation) = self.innovation_history.get(innovation_key) {
            innovation
        } else {
            let innovation = self.next_innovation;
            self.next_innovation += 1;
            self.innovation_history.insert(innovation_key.to_string(), innovation);
            innovation
        }
    }
}

/// Convergence metrics for evolution monitoring
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConvergenceMetrics {
    /// Fitness improvement rate
    pub improvement_rate: f32,
    /// Generations without improvement
    pub stagnation_count: usize,
    /// Population diversity trend
    pub diversity_trend: Vec<f32>,
    /// Convergence probability
    pub convergence_probability: f32,
}

/// Fitness evaluator for architecture candidates
pub struct FitnessEvaluator {
    /// Evaluation datasets
    datasets: HashMap<String, EvaluationDataset>,
    /// Hardware profiler
    hardware_profiler: HardwareProfiler,
    /// Evaluation cache
    evaluation_cache: Arc<RwLock<HashMap<String, PerformanceMetrics>>>,
}

/// Dataset for architecture evaluation
#[derive(Debug, Clone)]
pub struct EvaluationDataset {
    /// Dataset name
    pub name: String,
    /// Training triples
    pub train_triples: Vec<(String, String, String)>,
    /// Validation triples
    pub val_triples: Vec<(String, String, String)>,
    /// Test triples (optional)
    pub test_triples: Option<Vec<(String, String, String)>>,
    /// Entity vocabulary
    pub entity_vocab: HashSet<String>,
    /// Relation vocabulary
    pub relation_vocab: HashSet<String>,
}

/// Hardware profiler for performance measurement
pub struct HardwareProfiler {
    /// Target hardware configuration
    target_hardware: HardwareTarget,
    /// Profiling history
    profiling_history: Vec<ProfilingResult>,
}

/// Profiling result for hardware measurement
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProfilingResult {
    /// Architecture ID
    pub architecture_id: Uuid,
    /// Hardware metrics measured
    pub hardware_metrics: HardwareMetrics,
    /// Profiling timestamp
    pub timestamp: chrono::DateTime<chrono::Utc>,
    /// Profiling duration
    pub duration: Duration,
}

/// Genetic operators for evolution
pub struct GeneticOperators {
    /// Crossover operators
    crossover_ops: Vec<Box<dyn CrossoverOperator>>,
    /// Mutation operators
    mutation_ops: Vec<Box<dyn MutationOperator>>,
    /// Selection operators
    selection_ops: Vec<Box<dyn SelectionOperator>>,
}

/// Trait for crossover operators
pub trait CrossoverOperator: Send + Sync {
    fn crossover(
        &self,
        parent1: &ArchitectureCandidate,
        parent2: &ArchitectureCandidate,
        innovation_tracker: &mut InnovationTracker,
    ) -> Result<(ArchitectureCandidate, ArchitectureCandidate)>;
}

/// Trait for mutation operators
pub trait MutationOperator: Send + Sync {
    fn mutate(
        &self,
        candidate: &mut ArchitectureCandidate,
        innovation_tracker: &mut InnovationTracker,
        mutation_rate: f32,
    ) -> Result<()>;
}

/// Trait for selection operators
pub trait SelectionOperator: Send + Sync {
    fn select(
        &self,
        population: &[ArchitectureCandidate],
        selection_size: usize,
    ) -> Vec<usize>;
}

/// Population diversity manager
pub struct DiversityManager {
    /// Diversity metrics
    diversity_metrics: DiversityMetrics,
    /// Novelty archive
    novelty_archive: Vec<ArchitectureCandidate>,
    /// Diversity maintenance strategies
    strategies: Vec<Box<dyn DiversityStrategy>>,
}

/// Diversity metrics for population analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DiversityMetrics {
    /// Genotypic diversity (genome differences)
    pub genotypic_diversity: f32,
    /// Phenotypic diversity (performance differences)
    pub phenotypic_diversity: f32,
    /// Novelty score distribution
    pub novelty_distribution: Vec<f32>,
    /// Population entropy
    pub population_entropy: f32,
}

/// Trait for diversity maintenance strategies
pub trait DiversityStrategy: Send + Sync {
    fn maintain_diversity(
        &self,
        population: &mut Vec<ArchitectureCandidate>,
        diversity_target: f32,
    ) -> Result<()>;
}

/// Hardware-aware optimizer
pub struct HardwareOptimizer {
    /// Target hardware configuration
    target_hardware: HardwareTarget,
    /// Hardware-specific optimization strategies
    optimization_strategies: Vec<Box<dyn HardwareOptimizationStrategy>>,
    /// Performance models for different hardware
    performance_models: HashMap<String, Box<dyn PerformanceModel>>,
}

/// Trait for hardware optimization strategies
pub trait HardwareOptimizationStrategy: Send + Sync {
    fn optimize_for_hardware(
        &self,
        genome: &mut ArchitectureGenome,
        target_hardware: &HardwareTarget,
    ) -> Result<OptimizationResult>;
}

/// Hardware optimization result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationResult {
    /// Expected performance improvement
    pub performance_improvement: f32,
    /// Hardware efficiency gain
    pub efficiency_gain: f32,
    /// Optimization confidence
    pub confidence: f32,
    /// Applied modifications
    pub modifications: Vec<String>,
}

/// Trait for hardware performance models
pub trait PerformanceModel: Send + Sync {
    fn predict_performance(
        &self,
        genome: &ArchitectureGenome,
        hardware: &HardwareTarget,
    ) -> Result<PerformanceMetrics>;
}

impl EvolutionaryNAS {
    /// Create a new evolutionary NAS engine
    pub fn new(config: EvolutionaryConfig) -> Result<Self> {
        let population = Arc::new(RwLock::new(Vec::new()));
        let performance_cache = Arc::new(RwLock::new(HashMap::new()));
        
        let evolution_history = EvolutionHistory {
            generation_stats: Vec::new(),
            hall_of_fame: VecDeque::new(),
            innovation_tracker: InnovationTracker::new(),
            convergence_metrics: ConvergenceMetrics {
                improvement_rate: 0.0,
                stagnation_count: 0,
                diversity_trend: Vec::new(),
                convergence_probability: 0.0,
            },
        };

        let fitness_evaluator = FitnessEvaluator {
            datasets: HashMap::new(),
            hardware_profiler: HardwareProfiler {
                target_hardware: config.target_hardware.clone(),
                profiling_history: Vec::new(),
            },
            evaluation_cache: performance_cache.clone(),
        };

        let genetic_operators = GeneticOperators {
            crossover_ops: Vec::new(),
            mutation_ops: Vec::new(),
            selection_ops: Vec::new(),
        };

        let diversity_manager = DiversityManager {
            diversity_metrics: DiversityMetrics {
                genotypic_diversity: 0.0,
                phenotypic_diversity: 0.0,
                novelty_distribution: Vec::new(),
                population_entropy: 0.0,
            },
            novelty_archive: Vec::new(),
            strategies: Vec::new(),
        };

        let hardware_optimizer = HardwareOptimizer {
            target_hardware: config.target_hardware.clone(),
            optimization_strategies: Vec::new(),
            performance_models: HashMap::new(),
        };

        Ok(Self {
            config,
            population,
            evolution_history,
            fitness_evaluator,
            genetic_operators,
            diversity_manager,
            hardware_optimizer,
            performance_cache,
        })
    }

    /// Initialize the population with random architectures
    pub async fn initialize_population(&mut self) -> Result<()> {
        info!("Initializing population with {} candidates", self.config.population_size);
        
        let mut population = self.population.write().await;
        population.clear();
        
        for i in 0..self.config.population_size {
            let candidate = self.generate_random_candidate(i)?;
            population.push(candidate);
        }
        
        info!("Population initialized successfully");
        Ok(())
    }

    /// Generate a random architecture candidate
    fn generate_random_candidate(&mut self, index: usize) -> Result<ArchitectureCandidate> {
        let mut random = Random::default();
        
        // Start with simple architectures and increase complexity
        let base_complexity = self.config.progressive_config.start_complexity;
        let complexity_variance = 2;
        let num_nodes = base_complexity + random.random_range(0, complexity_variance);
        
        let mut nodes = Vec::new();
        let mut connections = Vec::new();
        
        // Create nodes with random operations
        for i in 0..num_nodes {
            let operation = self.generate_random_operation(&mut random)?;
            let node = NodeGene {
                id: i,
                operation,
                parameters: self.generate_random_parameters(&mut random),
                active: true,
                innovation_number: self.evolution_history.innovation_tracker
                    .get_innovation_number(&format!("node_{}", i)),
            };
            nodes.push(node);
        }
        
        // Create random connections
        let num_connections = random.random_range(num_nodes, num_nodes * 2);
        for i in 0..num_connections {
            if nodes.len() >= 2 {
                let from_node = random.random_range(0, nodes.len() - 1);
                let to_node = random.random_range(from_node + 1, nodes.len());

                let connection = ConnectionGene {
                    from_node,
                    to_node,
                    weight: random.gen_range(-1.0..1.0),
                    active: true,
                    innovation_number: self.evolution_history.innovation_tracker
                        .get_innovation_number(&format!("conn_{}_{}", from_node, to_node)),
                };
                connections.push(connection);
            }
        }
        
        let genome = ArchitectureGenome {
            nodes,
            connections,
            global_params: GlobalParameters::default(),
            modules: Vec::new(),
        };
        
        Ok(ArchitectureCandidate {
            id: Uuid::new_v4(),
            genome,
            fitness: FitnessScores::default(),
            performance: None,
            generation: 0,
            parents: Vec::new(),
            novelty_score: 0.0,
            hardware_metrics: HardwareMetrics::default(),
        })
    }

    /// Generate a random operation type
    fn generate_random_operation(&self, random: &mut Random) -> Result<OperationType> {
        let operations = vec![
            OperationType::Linear { input_dim: 128, output_dim: 128 },
            OperationType::GraphConv { channels: 64, aggregation: "mean".to_string() },
            OperationType::Attention { heads: 8, embed_dim: 128 },
            OperationType::Activation { function: "relu".to_string() },
            OperationType::Normalization { method: "batch_norm".to_string() },
            OperationType::Dropout { rate: 0.1 },
            OperationType::SkipConnection,
        ];
        
        Ok(operations.choose(random).unwrap().clone())
    }

    /// Generate random parameters for an operation
    fn generate_random_parameters(&self, random: &mut Random) -> HashMap<String, f32> {
        let mut params = HashMap::new();
        params.insert("learning_rate".to_string(), random.gen_range(0.0001..0.01));
        params.insert("dropout_rate".to_string(), random.gen_range(0.0..0.5));
        params.insert("weight_decay".to_string(), random.gen_range(0.0..0.01));
        params
    }

    /// Run the evolutionary optimization process
    pub async fn evolve(&mut self) -> Result<ArchitectureCandidate> {
        info!("Starting evolutionary optimization for {} generations", self.config.max_generations);
        
        // Initialize population if empty
        if self.population.read().await.is_empty() {
            self.initialize_population().await?;
        }
        
        let mut best_candidate: Option<ArchitectureCandidate> = None;
        
        for generation in 0..self.config.max_generations {
            info!("Generation {}/{}", generation + 1, self.config.max_generations);
            
            // Evaluate population
            self.evaluate_population().await?;
            
            // Track generation statistics
            let gen_stats = self.calculate_generation_statistics(generation).await?;
            self.evolution_history.generation_stats.push(gen_stats);
            
            // Update best candidate
            let current_best = self.get_best_candidate().await?;
            if best_candidate.is_none() || 
               current_best.fitness.overall_fitness > best_candidate.as_ref().unwrap().fitness.overall_fitness {
                best_candidate = Some(current_best);
                info!("New best fitness: {:.4}", best_candidate.as_ref().unwrap().fitness.overall_fitness);
            }
            
            // Check convergence
            if self.check_convergence(generation).await? {
                info!("Convergence detected at generation {}", generation);
                break;
            }
            
            // Evolve to next generation
            self.evolve_next_generation().await?;
            
            // Maintain diversity
            self.maintain_population_diversity().await?;
            
            // Apply progressive complexification
            if self.config.progressive_config.enable_modular_building {
                self.apply_progressive_complexification(generation).await?;
            }
        }
        
        info!("Evolution completed");
        best_candidate.ok_or_else(|| anyhow!("No best candidate found"))
    }

    /// Evaluate the fitness of all candidates in the population
    async fn evaluate_population(&mut self) -> Result<()> {
        let mut population = self.population.write().await;
        
        for candidate in population.iter_mut() {
            // Check cache first
            let genome_hash = self.calculate_genome_hash(&candidate.genome);
            
            if let Some(cached_performance) = self.performance_cache.read().await.get(&genome_hash) {
                candidate.performance = Some(cached_performance.clone());
            } else {
                // Evaluate candidate
                let performance = self.evaluate_candidate_performance(candidate).await?;
                candidate.performance = Some(performance.clone());
                
                // Cache result
                self.performance_cache.write().await.insert(genome_hash, performance);
            }
            
            // Calculate fitness scores
            candidate.fitness = self.calculate_fitness_scores(candidate)?;
        }
        
        // Calculate Pareto ranks and crowding distances
        self.calculate_pareto_ranking(&mut population)?;
        
        Ok(())
    }

    /// Calculate a hash for the genome to enable caching
    fn calculate_genome_hash(&self, genome: &ArchitectureGenome) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        genome.nodes.len().hash(&mut hasher);
        genome.connections.len().hash(&mut hasher);
        // Add more genome characteristics to hash
        format!("{:x}", hasher.finish())
    }

    /// Evaluate the performance of a single candidate
    async fn evaluate_candidate_performance(&self, candidate: &ArchitectureCandidate) -> Result<PerformanceMetrics> {
        // Simulate architecture evaluation
        // In a real implementation, this would train and evaluate the architecture
        let mut random = Random::default();

        Ok(PerformanceMetrics {
            training_accuracy: random.gen_range(0.7..0.95),
            validation_accuracy: random.gen_range(0.65..0.9),
            test_accuracy: None,
            training_time: random.gen_range(100.0..1000.0),
            inference_time_ms: random.gen_range(0.1..10.0),
            memory_usage_mb: random.gen_range(100.0..2000.0),
            energy_consumption: Some(random.gen_range(10.0..100.0)),
            model_size: random.random_range(1000000, 50000000),
            flops: random.random_range(1000000, 100000000),
        })
    }

    /// Calculate fitness scores for a candidate
    fn calculate_fitness_scores(&self, candidate: &ArchitectureCandidate) -> Result<FitnessScores> {
        let performance = candidate.performance.as_ref()
            .ok_or_else(|| anyhow!("No performance metrics available"))?;
        
        let weights = &self.config.objective_weights;
        
        // Normalize metrics to [0, 1] range
        let accuracy = performance.validation_accuracy;
        let efficiency = 1.0 / (performance.inference_time_ms + 1.0); // Higher is better
        let memory_efficiency = 1.0 / (performance.memory_usage_mb / 1000.0 + 1.0); // Higher is better
        let simplicity = 1.0 / (candidate.genome.nodes.len() as f32 / 10.0 + 1.0); // Simpler is better
        let novelty = candidate.novelty_score;
        let hardware_compatibility = candidate.hardware_metrics.efficiency_score;
        
        let overall_fitness = 
            weights.accuracy_weight * accuracy +
            weights.efficiency_weight * efficiency +
            weights.memory_weight * memory_efficiency +
            weights.simplicity_weight * simplicity +
            weights.novelty_weight * novelty;
        
        Ok(FitnessScores {
            overall_fitness,
            accuracy,
            efficiency,
            memory_efficiency,
            simplicity,
            novelty,
            hardware_compatibility,
            pareto_rank: 0, // Will be calculated later
            crowding_distance: 0.0, // Will be calculated later
        })
    }

    /// Calculate Pareto ranking for multi-objective optimization
    fn calculate_pareto_ranking(&self, population: &mut [ArchitectureCandidate]) -> Result<()> {
        let n = population.len();
        let mut domination_count = vec![0; n];
        let mut dominated_solutions = vec![Vec::new(); n];
        let mut fronts = Vec::new();
        let mut current_front = Vec::new();
        
        // Calculate domination relationships
        for i in 0..n {
            for j in 0..n {
                if i != j {
                    if self.dominates(&population[i], &population[j]) {
                        dominated_solutions[i].push(j);
                    } else if self.dominates(&population[j], &population[i]) {
                        domination_count[i] += 1;
                    }
                }
            }
            
            if domination_count[i] == 0 {
                population[i].fitness.pareto_rank = 0;
                current_front.push(i);
            }
        }
        
        // Build Pareto fronts
        let mut front_number = 0;
        while !current_front.is_empty() {
            fronts.push(current_front.clone());
            let mut next_front = Vec::new();
            
            for &i in &current_front {
                for &j in &dominated_solutions[i] {
                    domination_count[j] -= 1;
                    if domination_count[j] == 0 {
                        population[j].fitness.pareto_rank = front_number + 1;
                        next_front.push(j);
                    }
                }
            }
            
            front_number += 1;
            current_front = next_front;
        }
        
        // Calculate crowding distances
        for front in fronts {
            self.calculate_crowding_distance(population, &front)?;
        }
        
        Ok(())
    }

    /// Check if candidate a dominates candidate b
    fn dominates(&self, a: &ArchitectureCandidate, b: &ArchitectureCandidate) -> bool {
        let a_better = 
            a.fitness.accuracy >= b.fitness.accuracy &&
            a.fitness.efficiency >= b.fitness.efficiency &&
            a.fitness.memory_efficiency >= b.fitness.memory_efficiency &&
            a.fitness.simplicity >= b.fitness.simplicity;
        
        let a_strictly_better = 
            a.fitness.accuracy > b.fitness.accuracy ||
            a.fitness.efficiency > b.fitness.efficiency ||
            a.fitness.memory_efficiency > b.fitness.memory_efficiency ||
            a.fitness.simplicity > b.fitness.simplicity;
        
        a_better && a_strictly_better
    }

    /// Calculate crowding distance for diversity preservation
    fn calculate_crowding_distance(&self, population: &mut [ArchitectureCandidate], front: &[usize]) -> Result<()> {
        let front_size = front.len();
        if front_size <= 2 {
            for &i in front {
                population[i].fitness.crowding_distance = f32::INFINITY;
            }
            return Ok(());
        }
        
        // Initialize crowding distances
        for &i in front {
            population[i].fitness.crowding_distance = 0.0;
        }
        
        // Calculate crowding distance for each objective
        let objectives = ["accuracy", "efficiency", "memory_efficiency", "simplicity"];
        
        for objective in objectives {
            // Sort by objective
            let mut sorted_indices = front.to_vec();
            sorted_indices.sort_by(|&a, &b| {
                let val_a = self.get_objective_value(&population[a], objective);
                let val_b = self.get_objective_value(&population[b], objective);
                val_a.partial_cmp(&val_b).unwrap_or(std::cmp::Ordering::Equal)
            });
            
            // Set boundary points to infinity
            population[sorted_indices[0]].fitness.crowding_distance = f32::INFINITY;
            population[sorted_indices[front_size - 1]].fitness.crowding_distance = f32::INFINITY;
            
            // Calculate crowding distance for interior points
            let obj_min = self.get_objective_value(&population[sorted_indices[0]], objective);
            let obj_max = self.get_objective_value(&population[sorted_indices[front_size - 1]], objective);
            let obj_range = obj_max - obj_min;
            
            if obj_range > 0.0 {
                for i in 1..front_size - 1 {
                    let next_obj = self.get_objective_value(&population[sorted_indices[i + 1]], objective);
                    let prev_obj = self.get_objective_value(&population[sorted_indices[i - 1]], objective);
                    population[sorted_indices[i]].fitness.crowding_distance += 
                        (next_obj - prev_obj) / obj_range;
                }
            }
        }
        
        Ok(())
    }

    /// Get objective value for crowding distance calculation
    fn get_objective_value(&self, candidate: &ArchitectureCandidate, objective: &str) -> f32 {
        match objective {
            "accuracy" => candidate.fitness.accuracy,
            "efficiency" => candidate.fitness.efficiency,
            "memory_efficiency" => candidate.fitness.memory_efficiency,
            "simplicity" => candidate.fitness.simplicity,
            _ => 0.0,
        }
    }

    /// Calculate generation statistics
    async fn calculate_generation_statistics(&self, generation: usize) -> Result<GenerationStatistics> {
        let population = self.population.read().await;
        
        let fitness_values: Vec<f32> = population.iter()
            .map(|c| c.fitness.overall_fitness)
            .collect();
        
        let best_fitness = fitness_values.iter().fold(0.0f32, |a, &b| a.max(b));
        let average_fitness = fitness_values.iter().sum::<f32>() / fitness_values.len() as f32;
        
        let variance = fitness_values.iter()
            .map(|&f| (f - average_fitness).powi(2))
            .sum::<f32>() / fitness_values.len() as f32;
        let fitness_std = variance.sqrt();
        
        let diversity_score = self.calculate_population_diversity(&population)?;
        
        Ok(GenerationStatistics {
            generation,
            best_fitness,
            average_fitness,
            fitness_std,
            diversity_score,
            new_innovations: 0, // Would track new innovations
            timestamp: chrono::Utc::now(),
        })
    }

    /// Calculate population diversity
    fn calculate_population_diversity(&self, population: &[ArchitectureCandidate]) -> Result<f32> {
        if population.len() < 2 {
            return Ok(0.0);
        }
        
        let mut total_distance = 0.0;
        let mut comparisons = 0;
        
        for i in 0..population.len() {
            for j in i + 1..population.len() {
                let distance = self.calculate_genome_distance(&population[i].genome, &population[j].genome)?;
                total_distance += distance;
                comparisons += 1;
            }
        }
        
        Ok(total_distance / comparisons as f32)
    }

    /// Calculate distance between two genomes
    fn calculate_genome_distance(&self, genome1: &ArchitectureGenome, genome2: &ArchitectureGenome) -> Result<f32> {
        // Simple distance based on structural differences
        let node_diff = (genome1.nodes.len() as f32 - genome2.nodes.len() as f32).abs();
        let conn_diff = (genome1.connections.len() as f32 - genome2.connections.len() as f32).abs();
        
        Ok((node_diff + conn_diff) / 10.0) // Normalize
    }

    /// Get the best candidate from the current population
    async fn get_best_candidate(&self) -> Result<ArchitectureCandidate> {
        let population = self.population.read().await;
        
        population.iter()
            .max_by(|a, b| a.fitness.overall_fitness.partial_cmp(&b.fitness.overall_fitness).unwrap())
            .cloned()
            .ok_or_else(|| anyhow!("Empty population"))
    }

    /// Check if evolution has converged
    async fn check_convergence(&self, generation: usize) -> Result<bool> {
        if generation < 10 {
            return Ok(false); // Need minimum generations
        }
        
        let recent_stats = &self.evolution_history.generation_stats;
        if recent_stats.len() < 10 {
            return Ok(false);
        }
        
        // Check for fitness stagnation
        let recent_best: Vec<f32> = recent_stats.iter()
            .rev()
            .take(10)
            .map(|s| s.best_fitness)
            .collect();
        
        let improvement = recent_best[0] - recent_best[9];
        
        Ok(improvement < 0.001) // Use hardcoded threshold for now
    }

    /// Evolve to the next generation
    async fn evolve_next_generation(&mut self) -> Result<()> {
        let mut current_population = self.population.write().await;
        let mut new_population = Vec::new();
        
        // Elite selection - preserve best candidates
        let elite_count = (current_population.len() as f32 * self.config.elite_percentage) as usize;
        current_population.sort_by(|a, b| 
            b.fitness.overall_fitness.partial_cmp(&a.fitness.overall_fitness).unwrap()
        );
        
        for i in 0..elite_count {
            new_population.push(current_population[i].clone());
        }
        
        // Generate offspring through crossover and mutation
        while new_population.len() < self.config.population_size {
            // Tournament selection
            let parent1_idx = self.tournament_selection(&current_population)?;
            let parent2_idx = self.tournament_selection(&current_population)?;
            
            let parent1 = &current_population[parent1_idx];
            let parent2 = &current_population[parent2_idx];
            
            // Crossover
            let mut random = Random::default();
            if random.random::<f32>() < self.config.crossover_probability {
                let (mut child1, mut child2) = self.crossover(parent1, parent2)?;

                // Mutation
                if random.random::<f32>() < self.config.mutation_probability {
                    self.mutate(&mut child1)?;
                }
                if random.random::<f32>() < self.config.mutation_probability {
                    self.mutate(&mut child2)?;
                }
                
                new_population.push(child1);
                if new_population.len() < self.config.population_size {
                    new_population.push(child2);
                }
            } else {
                // Just add parent with potential mutation
                let mut child = parent1.clone();
                child.id = Uuid::new_v4();
                child.parents = vec![parent1.id];
                
                if random.random::<f32>() < self.config.mutation_probability {
                    self.mutate(&mut child)?;
                }
                
                new_population.push(child);
            }
        }
        
        *current_population = new_population;
        Ok(())
    }

    /// Tournament selection
    fn tournament_selection(&self, population: &[ArchitectureCandidate]) -> Result<usize> {
        let mut random = Random::default();
        let mut best_idx = random.random_range(0, population.len());
        let mut best_fitness = population[best_idx].fitness.overall_fitness;

        for _ in 1..self.config.tournament_size {
            let idx = random.random_range(0, population.len());
            if population[idx].fitness.overall_fitness > best_fitness {
                best_idx = idx;
                best_fitness = population[idx].fitness.overall_fitness;
            }
        }
        
        Ok(best_idx)
    }

    /// Crossover operation
    fn crossover(
        &mut self,
        parent1: &ArchitectureCandidate,
        parent2: &ArchitectureCandidate,
    ) -> Result<(ArchitectureCandidate, ArchitectureCandidate)> {
        let mut child1 = parent1.clone();
        let mut child2 = parent2.clone();
        
        child1.id = Uuid::new_v4();
        child2.id = Uuid::new_v4();
        child1.parents = vec![parent1.id, parent2.id];
        child2.parents = vec![parent1.id, parent2.id];
        
        // Simple single-point crossover for nodes
        let mut random = Random::default();
        let crossover_point = random.random_range(1, parent1.genome.nodes.len().min(parent2.genome.nodes.len()));
        
        // Exchange nodes after crossover point
        for i in crossover_point..child1.genome.nodes.len().min(child2.genome.nodes.len()) {
            std::mem::swap(&mut child1.genome.nodes[i], &mut child2.genome.nodes[i]);
        }
        
        // Reset fitness (needs re-evaluation)
        child1.fitness = FitnessScores::default();
        child2.fitness = FitnessScores::default();
        child1.performance = None;
        child2.performance = None;
        
        Ok((child1, child2))
    }

    /// Mutation operation
    fn mutate(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        let mut random = Random::default();

        // Node mutation - modify operation parameters
        for node in &mut candidate.genome.nodes {
            if random.random::<f32>() < self.config.mutation_probability {
                for (_, value) in node.parameters.iter_mut() {
                    *value *= random.gen_range(0.8..1.2); // ±20% variation
                }
            }
        }
        
        // Connection mutation - modify weights
        for connection in &mut candidate.genome.connections {
            if random.random::<f32>() < self.config.mutation_probability {
                connection.weight += random.gen_range(-0.1..0.1);
                connection.weight = connection.weight.clamp(-2.0, 2.0);
            }
        }
        
        // Structural mutation - add/remove nodes/connections occasionally
        if random.random::<f32>() < 0.05 { // Low probability structural mutation
            self.structural_mutation(candidate)?;
        }
        
        // Reset fitness (needs re-evaluation)
        candidate.fitness = FitnessScores::default();
        candidate.performance = None;
        
        Ok(())
    }

    /// Structural mutation - add or remove nodes/connections
    fn structural_mutation(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        let mut random = Random::default();

        match random.random_range(0, 4) {
            0 => self.add_node_mutation(candidate)?,
            1 => self.add_connection_mutation(candidate)?,
            2 => self.remove_node_mutation(candidate)?,
            3 => self.remove_connection_mutation(candidate)?,
            _ => {}
        }
        
        Ok(())
    }

    /// Add node mutation
    fn add_node_mutation(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        let mut random = Random::default();
        let new_id = candidate.genome.nodes.len();
        
        let operation = self.generate_random_operation(&mut random)?;
        let node = NodeGene {
            id: new_id,
            operation,
            parameters: self.generate_random_parameters(&mut random),
            active: true,
            innovation_number: self.evolution_history.innovation_tracker
                .get_innovation_number(&format!("node_{}", new_id)),
        };
        
        candidate.genome.nodes.push(node);
        Ok(())
    }

    /// Add connection mutation
    fn add_connection_mutation(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        let mut random = Random::default();
        let num_nodes = candidate.genome.nodes.len();

        if num_nodes >= 2 {
            let from_node = random.random_range(0, num_nodes);
            let to_node = random.random_range(0, num_nodes);

            if from_node != to_node {
                let connection = ConnectionGene {
                    from_node,
                    to_node,
                    weight: random.gen_range(-1.0..1.0),
                    active: true,
                    innovation_number: self.evolution_history.innovation_tracker
                        .get_innovation_number(&format!("conn_{}_{}", from_node, to_node)),
                };
                
                candidate.genome.connections.push(connection);
            }
        }
        
        Ok(())
    }

    /// Remove node mutation
    fn remove_node_mutation(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        if candidate.genome.nodes.len() > 3 { // Keep minimum structure
            let mut random = Random::default();
            let remove_idx = random.random_range(0, candidate.genome.nodes.len());
            candidate.genome.nodes.remove(remove_idx);
            
            // Remove connections involving the removed node
            candidate.genome.connections.retain(|conn| 
                conn.from_node != remove_idx && conn.to_node != remove_idx
            );
        }
        
        Ok(())
    }

    /// Remove connection mutation
    fn remove_connection_mutation(&mut self, candidate: &mut ArchitectureCandidate) -> Result<()> {
        if !candidate.genome.connections.is_empty() {
            let mut random = Random::default();
            let remove_idx = random.random_range(0, candidate.genome.connections.len());
            candidate.genome.connections.remove(remove_idx);
        }
        
        Ok(())
    }

    /// Maintain population diversity
    async fn maintain_population_diversity(&mut self) -> Result<()> {
        let mut population = self.population.write().await;
        
        // Calculate novelty scores
        for candidate in population.iter_mut() {
            candidate.novelty_score = self.calculate_novelty_score(candidate, &population)?;
        }
        
        // Remove very similar candidates
        let mut to_remove = Vec::new();
        for i in 0..population.len() {
            for j in i + 1..population.len() {
                let distance = self.calculate_genome_distance(
                    &population[i].genome,
                    &population[j].genome,
                )?;
                
                if distance < 0.1 { // Very similar threshold
                    // Keep the one with better fitness
                    if population[i].fitness.overall_fitness < population[j].fitness.overall_fitness {
                        to_remove.push(i);
                    } else {
                        to_remove.push(j);
                    }
                }
            }
        }
        
        // Remove duplicates from removal list and sort in reverse order
        to_remove.sort();
        to_remove.dedup();
        to_remove.reverse();
        
        for idx in to_remove {
            if population.len() > self.config.population_size / 2 { // Keep minimum population
                population.remove(idx);
            }
        }
        
        Ok(())
    }

    /// Calculate novelty score for a candidate
    fn calculate_novelty_score(
        &self,
        candidate: &ArchitectureCandidate,
        population: &[ArchitectureCandidate],
    ) -> Result<f32> {
        let k = 15; // Number of nearest neighbors
        let mut distances = Vec::new();
        
        for other in population {
            if other.id != candidate.id {
                let distance = self.calculate_genome_distance(&candidate.genome, &other.genome)?;
                distances.push(distance);
            }
        }
        
        distances.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let novelty = if distances.len() >= k {
            distances.iter().take(k).sum::<f32>() / k as f32
        } else {
            distances.iter().sum::<f32>() / distances.len().max(1) as f32
        };
        
        Ok(novelty)
    }

    /// Apply progressive complexification
    async fn apply_progressive_complexification(&mut self, generation: usize) -> Result<()> {
        let complexity_increase = self.config.progressive_config.complexity_increase_rate * generation as f32;
        let max_nodes = (self.config.progressive_config.start_complexity as f32 + complexity_increase) as usize;
        let max_nodes = max_nodes.min(self.config.progressive_config.max_complexity);
        
        let mut population = self.population.write().await;
        
        for candidate in population.iter_mut() {
            let mut random = Random::default();
            if candidate.genome.nodes.len() < max_nodes && random.random::<f32>() < 0.1 {
                // Gradually add complexity
                self.add_node_mutation(candidate)?;
            }
        }
        
        Ok(())
    }

    /// Get evolution statistics
    pub fn get_evolution_statistics(&self) -> &[GenerationStatistics] {
        &self.evolution_history.generation_stats
    }

    /// Export the best architectures
    pub async fn export_best_architectures(&self, count: usize) -> Result<Vec<ArchitectureCandidate>> {
        let mut population = self.population.read().await.clone();
        population.sort_by(|a, b| 
            b.fitness.overall_fitness.partial_cmp(&a.fitness.overall_fitness).unwrap()
        );
        
        Ok(population.into_iter().take(count).collect())
    }
}

/// Unit tests
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_evolutionary_nas_creation() {
        let config = EvolutionaryConfig::default();
        let nas = EvolutionaryNAS::new(config);
        assert!(nas.is_ok());
    }

    #[tokio::test]
    async fn test_population_initialization() {
        let config = EvolutionaryConfig {
            population_size: 10,
            ..Default::default()
        };
        let mut nas = EvolutionaryNAS::new(config).unwrap();
        
        let result = nas.initialize_population().await;
        assert!(result.is_ok());
        
        let population = nas.population.read().await;
        assert_eq!(population.len(), 10);
    }

    #[tokio::test]
    async fn test_genome_distance_calculation() {
        let config = EvolutionaryConfig::default();
        let mut nas = EvolutionaryNAS::new(config).unwrap();
        
        let candidate1 = nas.generate_random_candidate(0).unwrap();
        let candidate2 = nas.generate_random_candidate(1).unwrap();
        
        let distance = nas.calculate_genome_distance(&candidate1.genome, &candidate2.genome);
        assert!(distance.is_ok());
        assert!(distance.unwrap() >= 0.0);
    }

    #[tokio::test]
    async fn test_fitness_calculation() {
        let config = EvolutionaryConfig::default();
        let nas = EvolutionaryNAS::new(config).unwrap();
        
        let mut candidate = ArchitectureCandidate {
            id: Uuid::new_v4(),
            genome: ArchitectureGenome {
                nodes: Vec::new(),
                connections: Vec::new(),
                global_params: GlobalParameters::default(),
                modules: Vec::new(),
            },
            fitness: FitnessScores::default(),
            performance: Some(PerformanceMetrics {
                training_accuracy: 0.85,
                validation_accuracy: 0.82,
                test_accuracy: None,
                training_time: 300.0,
                inference_time_ms: 2.5,
                memory_usage_mb: 500.0,
                energy_consumption: Some(50.0),
                model_size: 1000000,
                flops: 5000000,
            }),
            generation: 0,
            parents: Vec::new(),
            novelty_score: 0.5,
            hardware_metrics: HardwareMetrics::default(),
        };
        
        let fitness = nas.calculate_fitness_scores(&candidate);
        assert!(fitness.is_ok());
        assert!(fitness.unwrap().overall_fitness > 0.0);
    }

    #[tokio::test]
    async fn test_tournament_selection() {
        let config = EvolutionaryConfig::default();
        let nas = EvolutionaryNAS::new(config).unwrap();
        
        let mut population = Vec::new();
        for i in 0..10 {
            let mut candidate = ArchitectureCandidate {
                id: Uuid::new_v4(),
                genome: ArchitectureGenome {
                    nodes: Vec::new(),
                    connections: Vec::new(),
                    global_params: GlobalParameters::default(),
                    modules: Vec::new(),
                },
                fitness: FitnessScores {
                    overall_fitness: i as f32 * 0.1,
                    ..Default::default()
                },
                performance: None,
                generation: 0,
                parents: Vec::new(),
                novelty_score: 0.0,
                hardware_metrics: HardwareMetrics::default(),
            };
            population.push(candidate);
        }
        
        let selected = nas.tournament_selection(&population);
        assert!(selected.is_ok());
        assert!(selected.unwrap() < population.len());
    }
}